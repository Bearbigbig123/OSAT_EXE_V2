import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
from datetime import datetime, timedelta
import random

# è¨­å®šä¸­æ–‡å­—é«”
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

def generate_pattern_data(pattern, n_samples, base_value=10, sigma=1, decimals=2):
    """
    æ ¹æ“š pattern ç”Ÿæˆå°æ‡‰çš„æ¸¬è©¦æ•¸æ“š
    decimals åƒæ•¸ï¼šæ§åˆ¶å°æ•¸é»ä½æ•¸
    """
    np.random.seed(42 + hash(pattern) % 1000 + n_samples)
    
    n_samples = max(1, int(n_samples))
    
    if pattern == "Normal":
        data = np.random.normal(base_value, sigma, n_samples)
        
    elif pattern == "Skew-Right":
        data = np.random.gamma(2, sigma, n_samples) + base_value - 2*sigma
        
    elif pattern == "Skew-Left":
        data = -(np.random.gamma(2, sigma, n_samples) - 2*sigma) + base_value
        
    elif pattern == "Bimodal":
        n1 = n_samples // 2
        n2 = n_samples - n1
        data1 = np.random.normal(base_value - 2*sigma, sigma*0.5, n1)
        data2 = np.random.normal(base_value + 2*sigma, sigma*0.5, n2)
        data = np.concatenate([data1, data2])
        
    elif pattern == "Attribute":
        # é›¢æ•£å‹æ•¸æ“š
        categories = [
            round(base_value - sigma, decimals),
            round(base_value, decimals),
            round(base_value + sigma, decimals),
            round(base_value + 2*sigma, decimals),
            round(base_value - 2*sigma, decimals)
        ]
        weights = [0.1, 0.4, 0.3, 0.15, 0.05]
        data = np.random.choice(categories, n_samples, p=weights)
        
    elif pattern == "Constant":
        data = np.full(n_samples, base_value)
        
    elif pattern == "Near Constant":
        n_constant = int(n_samples * 0.95)
        n_variant = n_samples - n_constant
        data_constant = np.full(n_constant, base_value)
        step = 10**(-int(decimals))
        data_variant = np.full(n_variant, base_value + step) 
        data = np.concatenate([data_constant, data_variant])
        
    elif pattern == "Step":
        n_steps = random.randint(3, 6)
        step_size = n_samples // n_steps
        data = []
        for i in range(n_steps):
            level = base_value + (i - n_steps//2) * sigma * 0.8
            step_data = np.random.normal(level, sigma * 0.15, step_size)
            data.extend(step_data)
        remaining = n_samples - len(data)
        if remaining > 0:
            data.extend(np.random.normal(base_value, sigma * 0.15, remaining))
        data = np.array(data)
        
    elif pattern == "Step-Up":
        n_steps = random.randint(3, 5)
        step_size = n_samples // n_steps
        data = []
        for i in range(n_steps):
            level = base_value + i * sigma * 0.6
            step_data = np.random.normal(level, sigma * 0.15, step_size)
            data.extend(step_data)
        remaining = n_samples - len(data)
        if remaining > 0:
            data.extend(np.random.normal(base_value + (n_steps-1) * sigma * 0.6, sigma * 0.15, remaining))
        data = np.array(data)
        
    elif pattern == "Step-Down":
        n_steps = random.randint(3, 5)
        step_size = n_samples // n_steps
        data = []
        for i in range(n_steps):
            level = base_value - i * sigma * 0.6
            step_data = np.random.normal(level, sigma * 0.15, step_size)
            data.extend(step_data)
        remaining = n_samples - len(data)
        if remaining > 0:
            data.extend(np.random.normal(base_value - (n_steps-1) * sigma * 0.6, sigma * 0.15, remaining))
        data = np.array(data)
        
    elif pattern == "Cyclic":
        t = np.linspace(0, 4*np.pi, n_samples)
        amplitude = sigma * 2
        data = base_value + amplitude * np.sin(t) + np.random.normal(0, sigma*0.2, n_samples)
        
    elif pattern == "Trending-Up":
        slope = sigma * 2 / n_samples
        trend = np.arange(n_samples) * slope
        data = base_value - sigma + trend + np.random.normal(0, sigma*0.3, n_samples)
        
    elif pattern == "Trending-Down":
        slope = sigma * 2 / n_samples
        trend = np.arange(n_samples) * slope
        data = base_value + sigma - trend + np.random.normal(0, sigma*0.3, n_samples)
        
    elif pattern == "Outliers":
        data = np.random.normal(base_value, sigma*0.5, n_samples)
        n_outliers = max(1, min(int(n_samples * random.uniform(0.05, 0.1)), n_samples))
        outlier_indices = np.random.choice(n_samples, n_outliers, replace=False)
        outlier_direction = np.random.choice([-1, 1], n_outliers)
        data[outlier_indices] += outlier_direction * sigma * random.uniform(4, 6)
        
    elif pattern == "Multimodal":
        n_modes = random.randint(3, 4)
        data = []
        samples_per_mode = n_samples // n_modes
        for i in range(n_modes):
            center = base_value + (i - n_modes//2) * sigma * 1.5
            mode_data = np.random.normal(center, sigma*0.4, samples_per_mode)
            data.extend(mode_data)
        remaining = n_samples - len(data)
        if remaining > 0:
            data.extend(np.random.normal(base_value, sigma*0.4, remaining))
        data = np.array(data)
        
    elif pattern == "Random-Walk":
        data = [base_value]
        for _ in range(n_samples - 1):
            step = np.random.normal(0, sigma*0.3)
            data.append(data[-1] + step)
        data = np.array(data)
        
    elif pattern == "Spike":
        data = np.random.normal(base_value, sigma*0.5, n_samples)
        n_spikes = min(random.randint(2, 5), n_samples)
        spike_indices = np.random.choice(n_samples, n_spikes, replace=False)
        spike_magnitude = np.random.choice([-1, 1], n_spikes) * sigma * random.uniform(5, 8)
        data[spike_indices] += spike_magnitude
        
    elif pattern == "Exponential":
        data = np.random.exponential(sigma, n_samples) + base_value - sigma
        
    elif pattern == "Uniform":
        data = np.random.uniform(base_value - 2*sigma, base_value + 2*sigma, n_samples)
        
    elif pattern == "U-Shape":
        middle_samples = max(1, int(n_samples * 0.1))
        side_samples = (n_samples - middle_samples) // 2
        remaining = n_samples - middle_samples - 2 * side_samples
        data1 = np.random.normal(base_value - 2*sigma, sigma*0.5, side_samples)
        data2 = np.random.normal(base_value + 2*sigma, sigma*0.5, side_samples)
        data_middle = np.random.normal(base_value, sigma*0.3, middle_samples)
        if remaining > 0:
            data_extra = np.random.normal(base_value + 2*sigma, sigma*0.5, remaining)
            data = np.concatenate([data1, data2, data_middle, data_extra])
        else:
            data = np.concatenate([data1, data2, data_middle])
        
    elif pattern == "Sawtooth":
        n_cycles = random.randint(3, 6)
        samples_per_cycle = n_samples // n_cycles
        data = []
        for _ in range(n_cycles):
            cycle = np.linspace(base_value - sigma, base_value + sigma, samples_per_cycle)
            cycle += np.random.normal(0, sigma*0.1, samples_per_cycle)
            data.extend(cycle)
        remaining = n_samples - len(data)
        if remaining > 0:
            data.extend(np.linspace(base_value - sigma, base_value + sigma, remaining))
        data = np.array(data)
        
    elif pattern == "Chaos":
        parts = random.randint(3, 5)
        part_size = n_samples // parts
        data = []
        sub_patterns = ["Normal", "Uniform", "Exponential", "Spike"]
        for i in range(parts):
            sub_pattern = random.choice(sub_patterns)
            # Chaos å…§éƒ¨ä¹Ÿä½¿ç”¨ç›¸åŒçš„ decimals
            sub_data = generate_pattern_data(sub_pattern, part_size, base_value, sigma, decimals)
            data.extend(sub_data)
        remaining = n_samples - len(data)
        if remaining > 0:
            data.extend(np.random.normal(base_value, sigma, remaining))
        data = np.array(data)
        
    else:
        data = np.random.normal(base_value, sigma, n_samples)
    
    data = np.array(data)
    
    # é•·åº¦èª¿æ•´
    if len(data) < n_samples:
        shortage = n_samples - len(data)
        extra = np.random.normal(base_value, sigma, shortage)
        data = np.concatenate([data, extra])
    elif len(data) > n_samples:
        data = data[:n_samples]
    
    # æ‰“äº‚é †åº (é™¤éæ˜¯æœ‰åºçš„æ™‚é–“åºåˆ— Pattern)
    ordered_patterns = ["Step", "Step-Up", "Step-Down", "Cyclic", "Trending-Up", "Trending-Down", "Random-Walk", "Sawtooth"]
    if pattern not in ordered_patterns and len(data) > 1:
        np.random.shuffle(data)
        
    # æ•¸å€¼ä¸Šåš Rounding
    data = np.round(data, decimals)
    
    return data

def generate_test_charts():
    """ç”Ÿæˆ 200 å¼µæ¸¬è©¦åœ–è¡¨çš„é…ç½®å’Œæ•¸æ“š"""
    
    patterns = ["Normal", "Skew-Right", "Skew-Left", "Bimodal", "Attribute", "Constant", "Near Constant", 
                "Step", "Step-Up", "Step-Down", "Cyclic", "Trending-Up", "Trending-Down", 
                "Outliers", "Multimodal", "Random-Walk", "Spike", "Exponential", "Uniform", 
                "U-Shape", "Sawtooth", "Chaos"]
    
    sample_ranges = [
        (4, 10), (11, 19), (20, 49), (50, 99), 
        (100, 299), (300, 999), (1000, 3000)
    ]
    characteristics = ["Nominal", "Smaller", "Bigger"]
    
    # === ä¿®æ”¹ 1: è¨­å®š 1~5 ä½å°æ•¸é»çš„æ¬Šé‡ ===
    possible_decimals = [1, 2, 3, 4, 5] 
    # æ¬Šé‡åˆ†é… (æ‚¨å¯ä»¥ä¾éœ€æ±‚èª¿æ•´ï¼Œé€™è£¡å‡è¨­ 2,3 ä½æœ€å¸¸è¦‹)
    decimal_weights = [0.1, 0.3, 0.3, 0.2, 0.1]
    
    charts_info = []
    
    for i in range(1000):
        pattern = random.choice(patterns)
        sample_range = random.choice(sample_ranges)
        n_samples = random.randint(sample_range[0], sample_range[1])
        characteristic = random.choice(characteristics)
        
        # éš¨æ©Ÿæ±ºå®šé€™å¼µ Chart çš„å°æ•¸é»ä½æ•¸ (1~5)
        n_decimals = np.random.choice(possible_decimals, p=decimal_weights)
        resolution_value = 10 ** (-int(n_decimals))
        
        # åŸºç¤åƒæ•¸
        base_value = random.uniform(8, 12)
        sigma = random.uniform(0.5, 2.0)
        
        # ç”Ÿæˆæ•¸æ“š (å¸¶å…¥ decimals åƒæ•¸)
        data = generate_pattern_data(pattern, n_samples, base_value, sigma, decimals=n_decimals)
        
        # è¨­å®š Target å’Œç®¡åˆ¶ç·š (ä¹Ÿè¦ round åˆ°ç›¸åŒä½æ•¸)
        target = round(base_value, n_decimals)
        
        if characteristic == "Nominal":
            ori_ucl = round(target + 4.5 * sigma, n_decimals)
            ori_lcl = round(target - 4.5 * sigma, n_decimals)
        elif characteristic == "Smaller":
            ori_ucl = round(target + 4 * sigma, n_decimals)
            ori_lcl = round(target - 5.5 * sigma, n_decimals)
        else: # Bigger
            ori_ucl = round(target + 5.5 * sigma, n_decimals)
            ori_lcl = round(target - 4 * sigma, n_decimals)
            
        usl = round(ori_ucl + 2 * sigma, n_decimals)
        lsl = round(ori_lcl - 2 * sigma, n_decimals)
        
        chart_info = {
            'GroupName': f'TestGroup_{i//10 + 1}',
            'ChartName': f'Chart_{i+1:03d}',
            'ChartID': f'TC{i+1:03d}',
            'Material_no': f'MAT_{i+1:03d}',
            'Target': target,
            'UCL': ori_ucl,
            'LCL': ori_lcl,
            'USL': usl,
            'LSL': lsl,
            'Characteristics': characteristic,
            'DetectionLimit': round(target - 3.5 * sigma, n_decimals) if characteristic == 'Smaller' else None,
            'ExpectedPattern': pattern,
            'SampleCount': n_samples,
            'Resolution': resolution_value
        }
        
        charts_info.append(chart_info)
        
        start_date = datetime.now() - timedelta(days=365*2)
        dates = [start_date + timedelta(days=random.randint(0, 730)) for _ in range(n_samples)]
        dates.sort()
        
        # --- æ–°å¢ ByTool é‚è¼¯ ---
        # éš¨æ©Ÿæ±ºå®šé€™å¼µ Chart æ˜¯ç”±å“ªå¹¾å° Tool ç”Ÿç”¢çš„ (å‡è¨­æ¯å¼µåœ–è¡¨ç”± 2~4 å°æ©Ÿå™¨è¼ªæ›¿)
        num_tools = random.randint(2, 4)
        available_tools = [f"TOOL_{random.randint(101, 150):03d}" for _ in range(num_tools)]
        
        # ç‚ºæ¯ä¸€ç­†æ•¸æ“šéš¨æ©ŸæŒ‡æ´¾ä¸€å€‹æ©Ÿå° (ä¹Ÿå¯ä»¥ç”¨å¾ªç’°æŒ‡æ´¾ï¼Œé€™è£¡æ¡éš¨æ©ŸæŒ‡æ´¾æ¨¡æ“¬çœŸå¯¦è¼ªæ›¿)
        tools_col = [random.choice(available_tools) for _ in range(n_samples)]
        
        batch_ids = []
        for date in dates:
            date_str = date.strftime('%Y%m%d')
            sequence = random.randint(1, 999)
            batch_id = f"BATCH-{date_str}-{sequence:03d}"
            batch_ids.append(batch_id)
        
        csv_data = pd.DataFrame({
            'point_time': dates,
            'point_val': data,
            'Batch_ID': batch_ids,
            'ByTool': tools_col  # æ–°å¢çš„æ©Ÿå°æ¬„ä½
        })
        # -----------------------
        
        os.makedirs('input/raw_charts', exist_ok=True)
        csv_filename = f"input/raw_charts/{chart_info['GroupName']}_{chart_info['ChartName']}.csv"
        
        # === ä¿®æ”¹ 2: å¯«å…¥ CSV æ™‚å¼·åˆ¶æŒ‡å®š float_format ===
        # é€™æ¨£å¯ä»¥ç¢ºä¿è©²æª”æ¡ˆå…§çš„æ•¸å€¼éƒ½æœ‰çµ±ä¸€çš„å°æ•¸ä½æ•¸ (åŒ…å«è£œé›¶)
        csv_data.to_csv(csv_filename, index=False, float_format=f'%.{n_decimals}f')
    
    charts_df = pd.DataFrame(charts_info)
    os.makedirs('input', exist_ok=True)
    charts_df.to_excel('input/All_Chart_Information.xlsx', sheet_name='Chart', index=False)
    
    print(f"âœ… å·²ç”Ÿæˆ 200 å¼µæ¸¬è©¦åœ–è¡¨ (Resolution æ¨¡æ“¬ç¯„åœ: 1~5 ä½å°æ•¸)")
    print(f"ğŸ“Š Resolution åˆ†ä½ˆ:\n{charts_df['Resolution'].value_counts().sort_index()}")
    
    return charts_df

if __name__ == '__main__':
    print("ğŸš€ é–‹å§‹ç”Ÿæˆæ¸¬è©¦æ•¸æ“š...")
    generate_test_charts()
    print("âœ… æ¸¬è©¦æ•¸æ“šç”Ÿæˆå®Œæˆï¼è«‹åŸ·è¡Œä¸»ç¨‹å¼é€²è¡Œæ¸¬è©¦ã€‚")